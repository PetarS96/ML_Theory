{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TriTraining Model Theory**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "Tri-Training is a semi-supervised learning algorithm that involves training three classifiers independently and refining them iteratively through mutual agreement. Each classifier is trained on a different bootstrap sample of the labeled data and enhances itself using the predictions of the other two classifiers.\n",
    "\n",
    "The main idea is to:\n",
    "- Train three classifiers on different bootstrap samples.\n",
    "- Use the classifiers to predict labels for the unlabeled data.\n",
    "- Update each classifier with the confident predictions agreed upon by the other two classifiers.\n",
    "- Repeat the process iteratively to improve the classifiers.\n",
    "\n",
    "## Tri-Training Process\n",
    "1. **Initialization**:\n",
    "- Create three bootstrap samples from the labeled dataset.\n",
    "- Train a classifier on each bootstrap sample.\n",
    "\n",
    "2. **Iteration**:\n",
    "- Use each classifier to predict labels for the unlabeled data.\n",
    "- Identify the predictions where two classifiers agree.\n",
    "- Update the third classifier with the agreed-upon predictions.\n",
    "- Repeat until convergence or a stopping criterion is met.\n",
    "\n",
    "## Key Steps\n",
    "1. **Bootstrap Sampling**:\n",
    "- Generate three different bootstrap samples from the labeled dataset.\n",
    "- Train a separate classifier on each bootstrap sample.\n",
    "\n",
    "2. **Label Prediction**:\n",
    "- Each classifier predicts labels for the unlabeled data independently.\n",
    "\n",
    "3. **Agreement-Based Selection**:\n",
    "- Identify the predictions where two classifiers agree.\n",
    "- Use these agreed-upon predictions to update the third classifier.\n",
    "\n",
    "4. **Classifier Update**:\n",
    "- Incorporate the new labeled data into the training set of the third classifier.\n",
    "- Retrain the classifier with the updated training set.\n",
    "\n",
    "5. **Convergence**:\n",
    "- Repeat the process until the classifiers' performance stabilizes or the maximum number of iterations is reached.\n",
    "\n",
    "## Mathematical Formulation\n",
    "1. **Bootstrap Sampling**:\n",
    "- Create three bootstrap samples \\( D_1, D_2, D_3 \\) from the labeled dataset \\( D \\).\n",
    "\n",
    "2. **Agreement-Based Labeling**:\n",
    "- For each classifier \\( C_i \\), update its training set \\( D_i \\) with the predictions agreed upon by the other two classifiers \\( C_j \\) and \\( C_k \\):\n",
    "$$ D_i = D_i \\cup \\{(x, y) \\mid C_j(x) = C_k(x) = y \\text{ and } C_i(x) \\neq y \\} $$\n",
    "\n",
    "3. **Retraining**:\n",
    "- Retrain classifier \\( C_i \\) with the updated training set \\( D_i \\).\n",
    "\n",
    "## Advantages\n",
    "- Leverages both labeled and unlabeled data.\n",
    "- Reduces the risk of incorrect label propagation through mutual agreement.\n",
    "- Can improve classification performance with limited labeled data.\n",
    "\n",
    "## Applications\n",
    "- Text classification.\n",
    "- Image recognition.\n",
    "- Any domain with a large amount of unlabeled data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation for Tri-Training Classifier\n",
    "\n",
    "### 1. Accuracy Score\n",
    "Formula:\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "$$\n",
    "Description:\n",
    "- Accuracy measures the ratio of correct predictions to total predictions.\n",
    "- Commonly used as a primary metric for balanced datasets.\n",
    "Interpretation:\n",
    "- Higher accuracy indicates better overall performance.\n",
    "- Limitations:\n",
    "  - May not be suitable for imbalanced datasets.\n",
    "  - Should be used alongside other metrics for comprehensive evaluation.\n",
    "---\n",
    "\n",
    "### 2. Gini Impurity\n",
    "Formula:\n",
    "$$\n",
    "\\text{Gini} = 1 - \\sum_{i=1}^{c} (p_i)^2\n",
    "$$\n",
    "Description:\n",
    "- Gini Impurity measures the probability of incorrect classification of a randomly chosen element.\n",
    "- Used as a splitting criterion during tree construction.\n",
    "Interpretation:\n",
    "- Ranges from 0 (pure node) to 0.5 (maximum impurity for binary classification).\n",
    "- Lower values indicate better class separation.\n",
    "---\n",
    "\n",
    "### 3. Information Gain\n",
    "Formula:\n",
    "$$\n",
    "\\text{IG}(T,a) = H(T) - \\sum_{v \\in \\text{values}(a)} \\frac{|T_v|}{|T|} H(T_v)\n",
    "$$\n",
    "Description:\n",
    "- Information Gain measures the reduction in entropy after splitting on an attribute.\n",
    "- Alternative splitting criterion to Gini impurity.\n",
    "Interpretation:\n",
    "- Higher values indicate more informative splits.\n",
    "- Used to select the best features for splitting nodes.\n",
    "---\n",
    "\n",
    "### 4. Model Complexity Metrics\n",
    "Description:\n",
    "- Number of Iterations: The number of iterations required for the algorithm to converge.\n",
    "- Number of Label Changes: The total number of label changes during the training process.\n",
    "Interpretation:\n",
    "- Lower complexity often indicates better generalization.\n",
    "- Used for tuning hyperparameters and improving model efficiency.\n",
    "---\n",
    "\n",
    "### 5. Precision\n",
    "Formula:\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "$$\n",
    "Description:\n",
    "- Precision shows the accuracy of positive predictions.\n",
    "- Important when false positives are costly.\n",
    "Interpretation:\n",
    "- Higher precision means fewer false positive predictions.\n",
    "- Use case: Particularly important in medical diagnosis and spam detection.\n",
    "---\n",
    "\n",
    "### 6. Recall (Sensitivity)\n",
    "Formula:\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "$$\n",
    "Description:\n",
    "- Recall indicates the model's ability to identify all relevant cases.\n",
    "- Critical in scenarios where missing positive cases is costly.\n",
    "Interpretation:\n",
    "- Higher recall means fewer false negatives.\n",
    "- Use case: Essential in medical screening and fraud detection.\n",
    "---\n",
    "\n",
    "### 7. Feature Importance\n",
    "Formula:\n",
    "$$\n",
    "\\text{Importance}(x_i) = \\sum_{t \\in \\text{splits on }x_i} n_t \\cdot \\Delta\\text{impurity}\n",
    "$$\n",
    "Description:\n",
    "- Measures the contribution of each feature to the model's decisions.\n",
    "- Based on the total reduction in impurity from splits on each feature.\n",
    "Interpretation:\n",
    "- Higher values indicate more influential features.\n",
    "- Useful for feature selection and model understanding.\n",
    "---\n",
    "\n",
    "### 8. Cross-Validation Scores\n",
    "Description:\n",
    "- K-fold cross-validation provides robust performance estimates.\n",
    "- Includes metrics for each fold and their statistical distribution.\n",
    "Interpretation:\n",
    "- Low variance across folds indicates stable model performance.\n",
    "- High variance may suggest overfitting or data inconsistencies.\n",
    "---\n",
    "\n",
    "### 9. Confusion Matrix\n",
    "Description:\n",
    "- Provides detailed breakdown of prediction outcomes:\n",
    "  - True Positives (TP)\n",
    "  - True Negatives (TN)\n",
    "  - False Positives (FP)\n",
    "  - False Negatives (FN)\n",
    "Interpretation:\n",
    "- Helps identify specific types of errors.\n",
    "- Essential for understanding class-wise performance.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tritraining template [TriTrainingClassifier](https://github.com/lyttonhao/Tri-Training)\n",
    "\n",
    "### class tritraining.TriTrainingClassifier(*, base_estimator=None, max_iter=10)\n",
    "\n",
    "| **Parameter**               | **Description**                                                                                                                                        | **Default**      |\n",
    "|----------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|------------------|\n",
    "| `base_estimator`           | The base estimator to be used for tri-training.                                                                                                       | `None`           |\n",
    "| `max_iter`                 | The maximum number of tri-training iterations.                                                                                                        | `10`             |\n",
    "\n",
    "-\n",
    "\n",
    "| **Attribute**              | **Description**                                                                                                                                        |\n",
    "|----------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `base_estimators_`         | The base estimators clones.                                                                                                                           |\n",
    "| `transductions_`           | The predicted labels for the input data.                                                                                                              |\n",
    "| `n_iter_`                  | The number of iterations run.                                                                                                                          |\n",
    "\n",
    "-\n",
    "\n",
    "| **Method**                 | **Description**                                                                                                                                        |\n",
    "|----------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `fit(X, y)`                | Fit the tri-training classifier from the training set.                                                                                                |\n",
    "| `predict(X)`               | Predict class for X.                                                                                                                                  |\n",
    "| `predict_proba(X)`         | Predict class probabilities of the input samples X.                                                                                                   |\n",
    "| `score(X, y)`              | Returns the mean accuracy on the given test data and labels.                                                                                           |\n",
    "| `get_params()`             | Get parameters for this estimator.                                                                                                                     |\n",
    "| `set_params(**params)`     | Set the parameters of this estimator.                                                                                                                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XXXXXXXX regression - Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 29.44%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1266\n",
      "           0       0.24      1.00      0.38        42\n",
      "           1       0.25      1.00      0.40        46\n",
      "           2       0.33      1.00      0.49        58\n",
      "           3       0.28      1.00      0.43        49\n",
      "           4       0.30      1.00      0.46        53\n",
      "           5       0.33      1.00      0.50        62\n",
      "           6       0.27      1.00      0.43        49\n",
      "           7       0.34      1.00      0.50        61\n",
      "           8       0.30      0.98      0.46        54\n",
      "           9       0.31      0.98      0.48        57\n",
      "\n",
      "    accuracy                           0.29      1797\n",
      "   macro avg       0.27      0.91      0.41      1797\n",
      "weighted avg       0.09      0.29      0.14      1797\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/petar-ubuntu/Learning/ML_Theory/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/petar-ubuntu/Learning/ML_Theory/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/petar-ubuntu/Learning/ML_Theory/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Data Import\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Step 2: Data Processing\n",
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create a partially labeled dataset\n",
    "rng = np.random.RandomState(42)\n",
    "random_unlabeled_points = rng.rand(len(y)) < 0.7\n",
    "y[random_unlabeled_points] = -1  # Label some points as -1 (unlabeled)\n",
    "\n",
    "# Step 3: Model Definition and Training\n",
    "# Define three base classifiers\n",
    "clf1 = RandomForestClassifier(n_estimators=100)\n",
    "clf2 = SVC(probability=True, gamma='scale')\n",
    "clf3 = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Define self-training classifiers\n",
    "self_training_clf1 = SelfTrainingClassifier(clf1)\n",
    "self_training_clf2 = SelfTrainingClassifier(clf2)\n",
    "self_training_clf3 = SelfTrainingClassifier(clf3)\n",
    "\n",
    "# Train classifiers\n",
    "self_training_clf1.fit(X_scaled, y)\n",
    "self_training_clf2.fit(X_scaled, y)\n",
    "self_training_clf3.fit(X_scaled, y)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "# Predict with each classifier\n",
    "y_pred1 = self_training_clf1.predict(X_scaled)\n",
    "y_pred2 = self_training_clf2.predict(X_scaled)\n",
    "y_pred3 = self_training_clf3.predict(X_scaled)\n",
    "\n",
    "# Combine predictions (majority vote)\n",
    "y_pred = np.array([y_pred1, y_pred2, y_pred3])\n",
    "y_pred_combined = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=y_pred)\n",
    "\n",
    "y_true = digits.target\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_true, y_pred_combined)\n",
    "report = classification_report(y_true, y_pred_combined)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
