{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Self-Training Model Theory**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "Self-Training is a semi-supervised learning algorithm where a classifier is iteratively trained on its own most confident predictions. It uses a small labeled dataset to train an initial model, then labels the unlabeled data and incorporates the most confident predictions back into the training set.\n",
    "\n",
    "The main idea is to:\n",
    "- Train a classifier with the labeled data.\n",
    "- Predict labels for the unlabeled data.\n",
    "- Use the most confident predictions to augment the labeled dataset.\n",
    "- Repeat the process to refine the classifier.\n",
    "\n",
    "## Self-Training Process\n",
    "1. **Initialization**:\n",
    "- Start with a small labeled dataset and a large unlabeled dataset.\n",
    "- Train an initial classifier using the labeled data.\n",
    "\n",
    "2. **Iteration**:\n",
    "- Predict labels for the unlabeled data.\n",
    "- Select confident predictions to add to the labeled dataset.\n",
    "- Retrain the classifier with the expanded labeled dataset.\n",
    "- Repeat until convergence or a stopping criterion is met.\n",
    "\n",
    "## Key Steps\n",
    "1. **Initial Training**:\n",
    "- Train a classifier using the labeled data.\n",
    "\n",
    "2. **Label Prediction**:\n",
    "- Use the trained classifier to predict labels for the unlabeled data.\n",
    "\n",
    "3. **Confident Selection**:\n",
    "- Identify the most confident predictions based on a confidence threshold.\n",
    "\n",
    "4. **Dataset Augmentation**:\n",
    "- Add the confident predictions to the labeled dataset.\n",
    "\n",
    "5. **Retraining**:\n",
    "- Retrain the classifier with the updated labeled dataset.\n",
    "- Repeat the process until convergence.\n",
    "\n",
    "## Mathematical Formulation\n",
    "1. **Confidence Measure**:\n",
    "- The confidence of a prediction can be measured using the probability of the predicted class:\n",
    "$$ \\text{Confidence}(x) = \\max(p(y|x)) $$\n",
    "\n",
    "2. **Threshold-Based Selection**:\n",
    "- Select predictions where the confidence exceeds a predefined threshold:\n",
    "$$ \\{(x, \\hat{y}) | \\text{Confidence}(x) > \\text{threshold} \\} $$\n",
    "\n",
    "## Advantages\n",
    "- Leverages both labeled and unlabeled data.\n",
    "- Can improve performance with limited labeled data.\n",
    "- Simple and easy to implement.\n",
    "\n",
    "## Applications\n",
    "- Text classification.\n",
    "- Image recognition.\n",
    "- Any domain with a large amount of unlabeled data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation for Self-Training Classifier\n",
    "\n",
    "### 1. Accuracy Score\n",
    "Formula:\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "$$\n",
    "Description:\n",
    "- Accuracy measures the ratio of correct predictions to total predictions.\n",
    "- Commonly used as a primary metric for balanced datasets.\n",
    "Interpretation:\n",
    "- Higher accuracy indicates better overall performance.\n",
    "- Limitations:\n",
    "  - May not be suitable for imbalanced datasets.\n",
    "  - Should be used alongside other metrics for comprehensive evaluation.\n",
    "---\n",
    "\n",
    "### 2. Gini Impurity\n",
    "Formula:\n",
    "$$\n",
    "\\text{Gini} = 1 - \\sum_{i=1}^{c} (p_i)^2\n",
    "$$\n",
    "Description:\n",
    "- Gini Impurity measures the probability of incorrect classification of a randomly chosen element.\n",
    "- Used as a splitting criterion during tree construction.\n",
    "Interpretation:\n",
    "- Ranges from 0 (pure node) to 0.5 (maximum impurity for binary classification).\n",
    "- Lower values indicate better class separation.\n",
    "---\n",
    "\n",
    "### 3. Information Gain\n",
    "Formula:\n",
    "$$\n",
    "\\text{IG}(T,a) = H(T) - \\sum_{v \\in \\text{values}(a)} \\frac{|T_v|}{|T|} H(T_v)\n",
    "$$\n",
    "Description:\n",
    "- Information Gain measures the reduction in entropy after splitting on an attribute.\n",
    "- Alternative splitting criterion to Gini impurity.\n",
    "Interpretation:\n",
    "- Higher values indicate more informative splits.\n",
    "- Used to select the best features for splitting nodes.\n",
    "---\n",
    "\n",
    "### 4. Model Complexity Metrics\n",
    "Description:\n",
    "- Number of Iterations: The number of iterations required for the algorithm to converge.\n",
    "- Number of Label Changes: The total number of label changes during the training process.\n",
    "Interpretation:\n",
    "- Lower complexity often indicates better generalization.\n",
    "- Used for tuning hyperparameters and improving model efficiency.\n",
    "---\n",
    "\n",
    "### 5. Precision\n",
    "Formula:\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "$$\n",
    "Description:\n",
    "- Precision shows the accuracy of positive predictions.\n",
    "- Important when false positives are costly.\n",
    "Interpretation:\n",
    "- Higher precision means fewer false positive predictions.\n",
    "- Use case: Particularly important in medical diagnosis and spam detection.\n",
    "---\n",
    "\n",
    "### 6. Recall (Sensitivity)\n",
    "Formula:\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "$$\n",
    "Description:\n",
    "- Recall indicates the model's ability to identify all relevant cases.\n",
    "- Critical in scenarios where missing positive cases is costly.\n",
    "Interpretation:\n",
    "- Higher recall means fewer false negatives.\n",
    "- Use case: Essential in medical screening and fraud detection.\n",
    "---\n",
    "\n",
    "### 7. Feature Importance\n",
    "Formula:\n",
    "$$\n",
    "\\text{Importance}(x_i) = \\sum_{t \\in \\text{splits on }x_i} n_t \\cdot \\Delta\\text{impurity}\n",
    "$$\n",
    "Description:\n",
    "- Measures the contribution of each feature to the model's decisions.\n",
    "- Based on the total reduction in impurity from splits on each feature.\n",
    "Interpretation:\n",
    "- Higher values indicate more influential features.\n",
    "- Useful for feature selection and model understanding.\n",
    "---\n",
    "\n",
    "### 8. Cross-Validation Scores\n",
    "Description:\n",
    "- K-fold cross-validation provides robust performance estimates.\n",
    "- Includes metrics for each fold and their statistical distribution.\n",
    "Interpretation:\n",
    "- Low variance across folds indicates stable model performance.\n",
    "- High variance may suggest overfitting or data inconsistencies.\n",
    "---\n",
    "\n",
    "### 9. Confusion Matrix\n",
    "Description:\n",
    "- Provides detailed breakdown of prediction outcomes:\n",
    "  - True Positives (TP)\n",
    "  - True Negatives (TN)\n",
    "  - False Positives (FP)\n",
    "  - False Negatives (FN)\n",
    "Interpretation:\n",
    "- Helps identify specific types of errors.\n",
    "- Essential for understanding class-wise performance.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn template [SelfTrainingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.SelfTrainingClassifier.html)\n",
    "\n",
    "### class sklearn.semi_supervised.SelfTrainingClassifier(*, base_estimator=None, threshold=0.75, criterion='k_best', k_best=10, max_iter=10, verbose=False)\n",
    "\n",
    "| **Parameter**               | **Description**                                                                                                                                        | **Default**      |\n",
    "|----------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|------------------|\n",
    "| `base_estimator`           | The base estimator to be used for self-training.                                                                                                      | `None`           |\n",
    "| `threshold`                | Confidence threshold for predicting a label.                                                                                                          | `0.75`           |\n",
    "| `criterion`                | The criterion to use to stop the self-training iterations. Options: 'threshold', 'k_best'.                                                           | `k_best`         |\n",
    "| `k_best`                   | The number of samples to predict at each iteration if `criterion='k_best'`.                                                                            | `10`             |\n",
    "| `max_iter`                 | The maximum number of self-training iterations.                                                                                                       | `10`             |\n",
    "| `verbose`                  | Whether to output verbose information.                                                                                                                | `False`          |\n",
    "\n",
    "-\n",
    "\n",
    "| **Attribute**              | **Description**                                                                                                                                        |\n",
    "|----------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `base_estimator_`          | The base estimator clone.                                                                                                                             |\n",
    "| `transduction_`            | The predicted labels for the input data.                                                                                                              |\n",
    "| `n_iter_`                  | The number of iterations run.                                                                                                                          |\n",
    "\n",
    "-\n",
    "\n",
    "| **Method**                 | **Description**                                                                                                                                        |\n",
    "|----------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `fit(X, y)`                | Fit the self-training classifier from the training set.                                                                                               |\n",
    "| `predict(X)`               | Predict class for X.                                                                                                                                  |\n",
    "| `predict_proba(X)`         | Predict class probabilities of the input samples X.                                                                                                   |\n",
    "| `score(X, y)`              | Returns the mean accuracy on the given test data and labels.                                                                                           |\n",
    "| `get_params()`             | Get parameters for this estimator.                                                                                                                     |\n",
    "| `set_params(**params)`     | Set the parameters of this estimator.                                                                                                                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XXXXXXXX regression - Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 29.44%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1266\n",
      "           0       0.24      1.00      0.38        42\n",
      "           1       0.25      1.00      0.40        46\n",
      "           2       0.33      1.00      0.50        58\n",
      "           3       0.28      1.00      0.43        49\n",
      "           4       0.29      1.00      0.45        53\n",
      "           5       0.34      1.00      0.50        62\n",
      "           6       0.27      1.00      0.43        49\n",
      "           7       0.35      1.00      0.52        61\n",
      "           8       0.30      0.98      0.46        54\n",
      "           9       0.30      0.98      0.46        57\n",
      "\n",
      "    accuracy                           0.29      1797\n",
      "   macro avg       0.27      0.91      0.41      1797\n",
      "weighted avg       0.09      0.29      0.14      1797\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/petar-ubuntu/Learning/ML_Theory/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/petar-ubuntu/Learning/ML_Theory/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/petar-ubuntu/Learning/ML_Theory/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Data Import\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Step 2: Data Processing\n",
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create a partially labeled dataset\n",
    "rng = np.random.RandomState(42)\n",
    "random_unlabeled_points = rng.rand(len(y)) < 0.7\n",
    "y[random_unlabeled_points] = -1  # Label some points as -1 (unlabeled)\n",
    "\n",
    "# Step 3: Model Definition and Training\n",
    "# Using SVM as the base estimator\n",
    "base_estimator = SVC(probability=True, gamma='scale')\n",
    "\n",
    "# Self-training classifier\n",
    "self_training_model = SelfTrainingClassifier(base_estimator)\n",
    "self_training_model.fit(X_scaled, y)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "y_pred = self_training_model.predict(X_scaled)\n",
    "y_true = digits.target\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
